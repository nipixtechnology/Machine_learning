{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf1f Ensemble Methods: Bagging, Boosting & Intro to XGBoost\n", "This notebook helps beginners understand:\n", "- What are Ensemble Methods?\n", "- Bagging using Random Forest\n", "- Boosting using AdaBoost\n", "- Intro to XGBoost\n", "- Visual comparison of model performance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install xgboost matplotlib scikit-learn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.datasets import make_classification\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n", "from sklearn.metrics import accuracy_score\n", "import xgboost as xgb"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83c\udfaf Generate Classification Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83c\udf32 Bagging with Random Forest"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n", "rf_model.fit(X_train, y_train)\n", "rf_pred = rf_model.predict(X_test)\n", "rf_acc = accuracy_score(y_test, rf_pred)\n", "print(\"Random Forest Accuracy:\", rf_acc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 Boosting with AdaBoost"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ab_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n", "ab_model.fit(X_train, y_train)\n", "ab_pred = ab_model.predict(X_test)\n", "ab_acc = accuracy_score(y_test, ab_pred)\n", "print(\"AdaBoost Accuracy:\", ab_acc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u26a1 Intro to XGBoost"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, use_label_encoder=False, eval_metric='logloss')\n", "xgb_model.fit(X_train, y_train)\n", "xgb_pred = xgb_model.predict(X_test)\n", "xgb_acc = accuracy_score(y_test, xgb_pred)\n", "print(\"XGBoost Accuracy:\", xgb_acc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcca Compare Model Accuracies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = ['Random Forest', 'AdaBoost', 'XGBoost']\n", "accuracies = [rf_acc, ab_acc, xgb_acc]\n", "\n", "plt.figure(figsize=(8,5))\n", "plt.bar(models, accuracies, color=['green', 'orange', 'blue'])\n", "plt.ylabel('Accuracy')\n", "plt.title('Model Comparison: Bagging vs Boosting')\n", "plt.ylim(0.8, 1.0)\n", "plt.grid(True)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}